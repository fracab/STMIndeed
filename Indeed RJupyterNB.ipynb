{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "STM is a text mining technique, initially conceived for the analysis of political texts, which has been extensively adopted in social sciences (<a href=\"https://www.structuraltopicmodel.com/\">here</a> you can find a list of the main publications that have adopted STM). As other topic models, like Latent Dirichlet Allocation it basically allows to identify abstract \"topics\" that occur in a collection of documents, but compared to other models, it allows the analysis of relationships with document metadata, in form of co-variates, either in terms of the degree of association of a document to a topic, either of the association of a word to a topic. As an example, it is possible to take a bunch of posts published on different political blogs in the months before an election, and see which topics were prevalent in the posts of blogs of a certain political leaning (in this case, political leaning of the blog is used as co-variate for topical prevalence), or to see how words associated to the treatment of a specific topic change depending to the political affiliation (in this case, political leaning of the blog is used as co-variate for topical content) (you can refer to the  <a href=\"https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf\">R package vignette</a> for more details).\n",
    "\n",
    "As I will stress all over, as the sample is totally arbitrary, any result will not have any statistical validity whatsoever. This is simply meant to be an attempt to explore a technique (and a R package) which can have several potential applications, both in terms of analytical purposes, both in terms of information visualisation (allowing for example to get over the use and abused word cloud). \n",
    "\n",
    "As many topics in data analysis, it is something easier to do rather than to explain, and something that can be really understood only when you get your hands dirty with some data, which is what prompted me to try this. In this and the following entries, I will try my hand and post the results of some attempts I am making with STM, more specifically testing the model on some job offers extracted from Indeed UK. As this is a work in progress, I will post the results of my work as I get through them, so I am not really sure where this will lead, but I hope to have some fun along the way. \n",
    "\n",
    "\n",
    "## Part I - Web Scraping\n",
    "\n",
    "In this first post I will not really get my hands on STM yet, but I will illustrate how I obtained the textual data I will use in the rest of the work. As mentioned above, I decided to focus on job offers: there is no specific reason for this, other than that I considered this a good example of texts that offer some metadata to incorporate in the analysis (type of job, salary, location), and whose topicality identification could represent a good test for the model. The choice fell on indeed.co.uk also for no specific reason, and I stuck to it after I noticed that scraping it was relatively easy (although the quality of metadata, as we will see later on, is not the best we could have hoped for). \n",
    "Obviously, if I had access to indeed.co.uk API this whole process would have been probably quicker, but since I don’t, I scraping the site was the only feasible option. \n",
    "The first step was to create three accessory functions to obtain from each offer page the information needed. This was relatively easily done thanks to htmlParse from XML package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary libraries\n",
    "suppressWarnings(library(rvest))\n",
    "suppressWarnings(library(\"xml2\"))\n",
    "suppressWarnings(library(\"XML\"))\n",
    "suppressWarnings(library(\"stringr\"))\n",
    "suppressWarnings(library(dplyr))\n",
    "suppressWarnings(library(naniar))\n",
    "\n",
    "## Scrape the info from pages:\n",
    "#metadata \n",
    "getmetadataindeed<-function(url){\n",
    "  meta<-read_html(url)%>%\n",
    "    htmlParse( asText=TRUE)%>%xpathSApply( \"//*[contains(@class,'jobsearch-JobMetadataHeader-iconLabel')]\", xmlValue)\n",
    "  if (is.list(meta)) {meta<-NA\n",
    "  } #as not all the job descriptions contain metadata, this was introduced to avoid ending up with empty lists in the dataframe\n",
    "meta \n",
    "  }\n",
    "\n",
    "#job description\n",
    "getjobdescindeed<-function(url){\n",
    "  read_html(url)%>%\n",
    "    htmlParse( asText=TRUE)%>%xpathSApply( \"//*[contains(@id,'jobDescriptionText')]\", xmlValue)%>%paste(collapse=', ')%>%str_replace_all(\"\\n\", \" \")\n",
    "  \n",
    "}\n",
    "\n",
    "#job title \n",
    "getjobtitle<-function(url){\n",
    "  tit<-read_html(url)%>%\n",
    "    htmlParse( asText=TRUE)%>%xpathSApply( \"//*[contains(@class, 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title')]\", xmlValue)\n",
    "  if (is.list(tit)) {\n",
    "    tit<-NA\n",
    "  }\n",
    "  tit\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these functions need to be fed with the specific URLs of the job offer webpages, and do this by hand for hundreds of offers is not really an option, I created a second function to directly scrape the URLs from the results page of a search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "getlinks<-function(url){\n",
    "  linksb<-read_html(url)%>%htmlParse(asText = TRUE)%>%xmlRoot()%>%xpathSApply(\"//*[contains(@class,'title')]\", xmlGetAttr, 'href')\n",
    "  linksb[sapply(linksb, is.null)] <- NULL\n",
    "  linksb<-as.character(linksb)\n",
    "  linksb<-paste(\"https://www.indeed.co.uk\", linksb,sep=\"\")\n",
    "    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, as some sponsored links are always present in the results page, the total number of job offer URLs scraped is slightly superior to the expected number, which for our purpose doesn’t really create particular issues. The final step was to put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapeindeed<-function(urlres) {\n",
    "  linksbb<-getlinks(urlres)\n",
    "  jobtitles<-lapply(FUN=getjobtitle, linksbb)%>%plyr::ldply(rbind)%>%mutate_if(is.factor,as.character)\n",
    "  jobsdesc<-lapply (FUN=getjobdescindeed, linksbb)%>%plyr::ldply(rbind)%>%mutate_if(is.factor,as.character)\n",
    "  jobmeta<-lapply (FUN=getmetadataindeed, linksbb)%>%plyr::ldply(rbind)%>%mutate_if(is.factor,as.character)\n",
    "  tobemoved <- grepl(\"£\", jobmeta[,2])#as salary can fall in the second column if location is missing, single out all the salary entries…\n",
    "  jobmeta[tobemoved,3 ]<-jobmeta[tobemoved,2 ] #...to move them to the third column\n",
    "  jobmeta[tobemoved,2 ] <-NA #leaving a NA on their place in the second column \n",
    "  final<-cbind(jobtitles,jobsdesc,jobmeta)%>%`colnames<-`(c(\"Title\", \"Description\", \"Location\",\"Type\",\"Salary\"))\n",
    "  final\n",
    "}\n",
    "\n",
    "###############\n",
    "#test \n",
    "##\n",
    "results1<-scrapeindeed(\"https://www.indeed.co.uk/jobs?as_and=&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&as_src=&salary=&radius=25&l=ne18&fromage=3&limit=50&sort=&psf=advsrch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Title \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Leaflet Distributors \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Description \n",
      " We require reliable adults who enjoy walking and being outside. The work involves delivering leaflets for a national home improvement PLC company Door to Door in Sunderland and surrounding areas. You can work in your own area or if you have a car we can send you to nearby locations or villages. If you have a car we can supply you with enough work to keep you busy for up to 5 days per week. We are particularly interested in retired people, semi-retired, stay at home parent or college/university students. Ideally, you will be prepared to do a minimum of 12 hours per week. Payments from £60 per week to £250 depending upon hours worked. If your able to work full time a car may be provided for suitable applicant. Job Type / Category The hours worked are flexible and can be planned by yourself, as long as you meet the date specified for completion. Benefits Get paid to exercise and enjoy fresh air Job Types: Full-time, Part-time Location: Sunderland SR1 (Preferred) \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Location \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Sunderland SR1 \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Type \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Part-time \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Salary \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n"
     ]
    }
   ],
   "source": [
    "print.table(results1[1,], justify=\"left\", width=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, fed with the URL of the results page, can extract all the data needed and store them in a dataframe of five columns. The last step was to fed the function with all the results pages relevant, which I did (in this case manually), for all the job offers published in the last three days before Saturday 18th May within 25 miles of the postcode NE18 (Newcastle Upon Tyne). The results were then merged together, the data are available <a href=\"https://www.dropbox.com/s/fa3hhcfi5qkqfp1/totaljobs.txt?dl=0\">here</a>  in .txt format.\n",
    "\n",
    "As you can see, there is still much to do in terms of data cleaning before starting to work, which is what we will see in the next section. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
